# LLM-Paper-List
本项目旨在对LLM相关的论文进行整理和分类。

## Table of Contents
- Survey(#survey)
- Model(#model)
- VLM(#vlm)
- Hallucination(#hallucination)

## Survey
- [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://arxiv.org/pdf/2107.13586.pdf) *Pengfei Liu, Weizhe Yuan, Jinlan Fu, and etc.*
- [Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models](https://arxiv.org/pdf/2309.01219.pdf) *Yue Zhang, Yafu Li, Leyang Cui, and etc.*
- [Automatically Correcting Large Language Models:Surveying the landscape of diverse self-correction strategies](https://arxiv.org/pdf/2308.03188.pdf) *Liangming Pan, Michael Saxon, Wenda Xu, and etc.*
- [A Survey on In-context Learning](https://arxiv.org/pdf/2301.00234.pdf) *Qingxiu Dong, Lei Li, Damai Dai, and etc.*
- [A Survey of Large Language Models](https://arxiv.org/pdf/2303.18223.pdf) *Wayne Xin Zhao, Kun Zhou, Junyi Li, and etc.*
- [Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents](https://arxiv.org/pdf/2311.11797.pdf) *Zhuosheng Zhang, Yao Yao, Aston Zhang, and etc.*
- [Data Management For Large Language Models: A Survey](https://arxiv.org/pdf/2312.01700.pdf) *Zige Wang, Wanjun Zhong, Yufei Wang, and etc.*
- [Survey of Hallucination in Natural Language Generation](https://arxiv.org/pdf/2202.03629.pdf) *Ziwei Ji, Nayeon Lee, Rita Frieske, and etc.*
- [Large Language Models for Robotics: A Survey](https://arxiv.org/pdf/2311.07226.pdf) *Fanlong Zeng, Wensheng Gan, Yongheng Wang, and etc.*

## Model
- [Gemini: A Family of Highly Capable Multimodal Models](https://arxiv.org/pdf/2312.11805.pdf) *Rohan Anil, Sebastian Borgeaud, Yonghui Wu, and etc.*
- [Gemma: Open Models Based on Gemini Research and Technology](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf) *Thomas Mesnard, Cassidy Hardin, Robert Dadashi, and etc.*
- [Mixtral of Experts](https://arxiv.org/pdf/2401.04088.pdf) *Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, and etc.*
- [Improving Language Understanding by Generative Pre-Training](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) *Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever*
- [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) *Alec Radford, Jeffrey Wu, Rewon Child, and etc.*
- [Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf) *Tom B. Brown, Benjamin Mann, Nick Ryder, and etc.*
- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf) *Ashish Vaswani, Noam Shazeer, Niki Parmar, and etc.*
- [BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/pdf/2211.05100.pdf) *Teven Le Scao, Angela Fan, Christopher Akiki, and etc.*
- [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/pdf/2302.13971.pdf) *Hugo Touvron, Thibaut Lavril, Gautier Izacard, and etc.*
- [PaLM: Scaling Language Modeling with Pathways](https://arxiv.org/pdf/2204.02311.pdf) *Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, and etc.*
- [GLM: General Language Model Pretraining with Autoregressive Blank Infilling](https://arxiv.org/pdf/2103.10360.pdf) *Zhengxiao Du, Yujie Qian, Xiao Liu, and etc.*
- [Unified Language Model Pre-training for Natural Language Understanding and Generation](https://arxiv.org/pdf/1905.03197.pdf) *Li Dong, Nan Yang, Wenhui Wang, and etc.*

## VLM
- [MoE-LLaVA: Mixture of Experts for Large Vision-Language Models](https://arxiv.org/pdf/2401.15947.pdf) *Bin Lin, Zhenyu Tang, Yang Ye, and etc.*
- [SimVLM: Simple Visual Language Model Pretraining with Weak Supervision](https://arxiv.org/pdf/2108.10904.pdf) *Zirui Wang, Jiahui Yu, Adams Wei Yu, and etc.*
- [CogVLM: Visual Expert for Pretrained Language Models](https://arxiv.org/pdf/2311.03079.pdf) *Weihan Wang, Qingsong Lv, Wenmeng Yu, and etc.*
- [MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action](https://arxiv.org/pdf/2303.11381.pdf) *Zhengyuan Yang, Linjie Li, Jianfeng Wang, and etc.*
- [Visual Programming: Compositional visual reasoning without training](https://arxiv.org/pdf/2211.11559.pdf) *Tanmay Gupta, Aniruddha Kembhavi*
- [Multimodal Few-Shot Learning with Frozen Language Models](https://arxiv.org/pdf/2106.13884.pdf) *Maria Tsimpoukelli, Jacob Menick, Serkan Cabi, and etc.*
- [VisualGPT: Data-efficient Adaptation of Pretrained Language Models for Image Captioning](https://arxiv.org/pdf/2102.10407.pdf) *Jun Chen, Han Guo, Kai Yi, and etc.*
- [InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning](https://arxiv.org/pdf/2305.06500.pdf) *Wenliang Dai, Junnan Li, Dongxu Li, and etc.*
- [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/pdf/2301.12597.pdf) *Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi*

## Hallucination
